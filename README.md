# Projet Fil Rouge â€“ PrÃ©diction de Trafic Routier

## ğŸ¯ Objectif

PrÃ©dire le niveau de trafic 1 heure Ã  lâ€™avance sur un axe parisien donnÃ©, en exploitant les donnÃ©es open data des capteurs permanents.

## ğŸ‘¥ Ã‰quipe

* MLOps : Ivan
* Lead Data : Ismael
* API : Mael
* RGPD/SÃ©curitÃ© : Merveille

## ğŸ“Š DonnÃ©es utilisÃ©es

* Source principale :
  Comptage Routier â€” Capteurs permanents (OpenData Paris)
  [opendata.paris.fr](https://opendata.paris.fr/explore/dataset/comptages-routiers-permanents/dataviz/?disjunctive.libelle&disjunctive.libelle_nd_amont&disjunctive.libelle_nd_aval&disjunctive.etat_trafic&sort=t_1h)
* Description : mesures en continu du trafic routier (intensitÃ©, timestamp, ID capteur).
* Format : CSV
* Champs principaux : `t_1h`, `id_nd`, `etat_trafic`, horodatage, intensitÃ© trafic.

## ğŸ§  KPI

MAE entre trafic prÃ©dit et rÃ©el (volume horaire).

## ğŸ“¦ Stack

FastAPI, MLflow, Docker, GitHub Actions, GCP/AWS Free Tier.

---

# ğŸš¦Info_Trafic â€“ Structure du projet

```text
project/
â”œâ”€ app.py                        # Script principal / orchestrateur
â”œâ”€ README.md                     # Documentation principale
â”œâ”€ .gitignore                    # Fichiers et dossiers Ã  ignorer par Git
â”œâ”€ docker-compose.yml            # Orchestration des conteneurs Docker
â”œâ”€ data/                         # DonnÃ©es : raw, processed, models, samples
â”œâ”€ docker/                       # Dockerfiles et requirements spÃ©cifiques
â”‚  â”œâ”€ Dockerfile.ingest
â”‚  â”œâ”€ Dockerfile.etl
â”‚  â”œâ”€ Dockerfile.training
â”‚  â”œâ”€ Dockerfile.front
â”‚  â””â”€ requirements/
â”œâ”€ src/                          # Code backend
â”‚  â”œâ”€ ingest/
â”‚  â”œâ”€ etl/
â”‚  â”œâ”€ training/
â”‚  â””â”€ utils/
â”œâ”€ frontend/                     # Interface utilisateur / dashboard
â”‚  â”œâ”€ app_front.py
â”‚  â”œâ”€ components/
â”‚  â””â”€ assets/
â””â”€ docs/                         # Documentation supplÃ©mentaire
````


## ğŸ³ Les diffÃ©rents conteneurs Docker et leur rÃ´le

Le projet est organisÃ© en **plusieurs conteneurs Docker**, chacun ayant une responsabilitÃ© spÃ©cifique. Cela permet dâ€™isoler les services, de faciliter le dÃ©veloppement et de partager les donnÃ©es via des volumes.

| Conteneur    | Dockerfile            | Dossier copiÃ©                  | Volumes utilisÃ©s                             | RÃ´le                                                                                      |
| ------------ | --------------------- | ------------------------------ | -------------------------------------------- | ----------------------------------------------------------------------------------------- |
| **ingest**   | `Dockerfile.ingest`   | `src/ingest/` + `src/utils/`   | `/app/raw`, `/app/samples`                   | Collecte les donnÃ©es depuis MQTT ou API et les stocke dans `raw/`.                        |
| **etl**      | `Dockerfile.etl`      | `src/etl/` + `src/utils/`      | `/app/raw`, `/app/processed`, `/app/samples` | Nettoie, transforme et enrichit les donnÃ©es.                                              |
| **training** | `Dockerfile.training` | `src/training/` + `src/utils/` | `/app/processed`, `/app/models`              | EntraÃ®ne les modÃ¨les ML et les sauvegarde dans `models/`.                                 |
| **front**    | `Dockerfile.front`    | `frontend/` + `src/utils/`     | `/app/processed`, `/app/models`              | Affiche les donnÃ©es et rÃ©sultats via lâ€™interface utilisateur (Streamlit ou autre).        |
| **api**      | `Dockerfile.api`      | `app.py`              | `-`                                  | Expose FastAPI pour dÃ©clencher le pipeline (ingest, ETL, training) via des requÃªtes HTTP. |

---

### Points importants

* Chaque conteneur **est isolÃ©** et a ses propres dÃ©pendances (`requirements.txt` spÃ©cifique).
* Les dossiers `raw/`, `processed/` et `models/` sont **mutualisÃ©s via des volumes**, permettant la communication entre conteneurs.
* Cela permet de **lancer uniquement un service** pour le dÃ©veloppement ou le test, sans reconstruire tout le pipeline.
* Le front peut accÃ©der aux donnÃ©es et modÃ¨les produits par les autres conteneurs en temps rÃ©el.
* Lâ€™API permet de **dÃ©clencher tout le pipeline** ou des parties spÃ©cifiques via des endpoints HTTP (`/ingest`, `/etl`, `/training`).

---

# â–¶ï¸ ExÃ©cuter le projet via Docker

## 1. Lancer tout le pipeline avec Docker Compose

Depuis la racine du projet, tu peux construire et dÃ©marrer **tous les services** (ingest, ETL, training, front, API) en une seule commande :

```bash
docker-compose up --build
```

* `--build` : reconstruit toutes les images avant de dÃ©marrer les conteneurs.
* Tous les conteneurs utilisent les volumes mutualisÃ©s (`data/raw`, `data/processed`, `data/models`).
* Le front (Streamlit) sera accessible sur le port dÃ©fini (ex. `8501`).
* Lâ€™API FastAPI sera accessible sur `http://localhost:8000` avec la documentation interactive `http://localhost:8000/docs`.

Pour lancer en arriÃ¨re-plan :

```bash
docker-compose up -d
```

---

## 2. Lancer un seul service

Si tu veux travailler sur **un service spÃ©cifique** sans dÃ©marrer tous les conteneurs :

```bash
docker-compose up --build etl
```

* Remplace `etl` par `ingest`, `training`, `front` ou `api` selon le service que tu veux lancer.
* Les autres conteneurs **ne seront pas dÃ©marrÃ©s**, mais les volumes nÃ©cessaires seront toujours accessibles.

---

## 3. AccÃ©der au terminal dâ€™un conteneur

Pour exÃ©cuter des commandes directement dans un conteneur en fonctionnement :

```bash
docker exec -it <nom_du_conteneur> /bin/bash
```

* Exemple pour ETL :

```bash
docker exec -it etl_container /bin/bash
```

* Tu peux ensuite naviguer dans le conteneur, lancer des scripts Python ou inspecter les fichiers montÃ©s dans `/app/raw`, `/app/processed`, etc.

---

## 4. AccÃ©der Ã  lâ€™interface Front

* Streamlit :

```text
http://localhost:8501
```

* API FastAPI :

```text
http://localhost:8000
```

* Documentation interactive (Swagger) :

```text
http://localhost:8000/docs
```